{
  "url": "https://fastapi.tiangolo.com/async/",
  "title": "Concurrency and async / awaitÂ¶",
  "content": "Details about the async def syntax for path operation functions and some background about asynchronous code, concurrency, and parallelism.\n\nIf you are using third party libraries that tell you to call them with await, like:\n\nThen, declare your path operation functions with async def like:\n\nYou can only use await inside of functions created with async def.\n\nIf you are using a third party library that communicates with something (a database, an API, the file system, etc.) and doesn't have support for using await, (this is currently the case for most database libraries), then declare your path operation functions as normally, with just def, like:\n\nIf your application (somehow) doesn't have to communicate with anything else and wait for it to respond, use async def, even if you don't need to use await inside.\n\nIf you just don't know, use normal def.\n\nNote: You can mix def and async def in your path operation functions as much as you need and define each one using the best option for you. FastAPI will do the right thing with them.\n\nAnyway, in any of the cases above, FastAPI will still work asynchronously and be extremely fast.\n\nBut by following the steps above, it will be able to do some performance optimizations.\n\nModern versions of Python have support for \"asynchronous code\" using something called \"coroutines\", with async and await syntax.\n\nLet's see that phrase by parts in the sections below:\n\nAsynchronous code just means that the language ğŸ’¬ has a way to tell the computer / program ğŸ¤– that at some point in the code, it ğŸ¤– will have to wait for something else to finish somewhere else. Let's say that something else is called \"slow-file\" ğŸ“.\n\nSo, during that time, the computer can go and do some other work, while \"slow-file\" ğŸ“ finishes.\n\nThen the computer / program ğŸ¤– will come back every time it has a chance because it's waiting again, or whenever it ğŸ¤– finished all the work it had at that point. And it ğŸ¤– will see if any of the tasks it was waiting for have already finished, doing whatever it had to do.\n\nNext, it ğŸ¤– takes the first task to finish (let's say, our \"slow-file\" ğŸ“) and continues whatever it had to do with it.\n\nThat \"wait for something else\" normally refers to I/O operations that are relatively \"slow\" (compared to the speed of the processor and the RAM memory), like waiting for:\n\nAs the execution time is consumed mostly by waiting for I/O operations, they call them \"I/O bound\" operations.\n\nIt's called \"asynchronous\" because the computer / program doesn't have to be \"synchronized\" with the slow task, waiting for the exact moment that the task finishes, while doing nothing, to be able to take the task result and continue the work.\n\nInstead of that, by being an \"asynchronous\" system, once finished, the task can wait in line a little bit (some microseconds) for the computer / program to finish whatever it went to do, and then come back to take the results and continue working with them.\n\nFor \"synchronous\" (contrary to \"asynchronous\") they commonly also use the term \"sequential\", because the computer / program follows all the steps in sequence before switching to a different task, even if those steps involve waiting.\n\nThis idea of asynchronous code described above is also sometimes called \"concurrency\". It is different from \"parallelism\".\n\nConcurrency and parallelism both relate to \"different things happening more or less at the same time\".\n\nBut the details between concurrency and parallelism are quite different.\n\nTo see the difference, imagine the following story about burgers:\n\nYou go with your crush to get fast food, you stand in line while the cashier takes the orders from the people in front of you. ğŸ˜\n\nThen it's your turn, you place your order of 2 very fancy burgers for your crush and you. ğŸ”ğŸ”\n\nThe cashier says something to the cook in the kitchen so they know they have to prepare your burgers (even though they are currently preparing the ones for the previous clients).\n\nThe cashier gives you the number of your turn.\n\nWhile you are waiting, you go with your crush and pick a table, you sit and talk with your crush for a long time (as your burgers are very fancy and take some time to prepare).\n\nAs you are sitting at the table with your crush, while you wait for the burgers, you can spend that time admiring how awesome, cute and smart your crush is âœ¨ğŸ˜âœ¨.\n\nWhile waiting and talking to your crush, from time to time, you check the number displayed on the counter to see if it's your turn already.\n\nThen at some point, it finally is your turn. You go to the counter, get your burgers and come back to the table.\n\nYou and your crush eat the burgers and have a nice time. âœ¨\n\nBeautiful illustrations by Ketrina Thompson. ğŸ¨\n\nImagine you are the computer / program ğŸ¤– in that story.\n\nWhile you are at the line, you are just idle ğŸ˜´, waiting for your turn, not doing anything very \"productive\". But the line is fast because the cashier is only taking the orders (not preparing them), so that's fine.\n\nThen, when it's your turn, you do actual \"productive\" work, you process the menu, decide what you want, get your crush's choice, pay, check that you give the correct bill or card, check that you are charged correctly, check that the order has the correct items, etc.\n\nBut then, even though you still don't have your burgers, your work with the cashier is \"on pause\" â¸, because you have to wait ğŸ•™ for your burgers to be ready.\n\nBut as you go away from the counter and sit at the table with a number for your turn, you can switch ğŸ”€ your attention to your crush, and \"work\" â¯ ğŸ¤“ on that. Then you are again doing something very \"productive\" as is flirting with your crush ğŸ˜.\n\nThen the cashier ğŸ’ says \"I'm finished with doing the burgers\" by putting your number on the counter's display, but you don't jump like crazy immediately when the displayed number changes to your turn number. You know no one will steal your burgers because you have the number of your turn, and they have theirs.\n\nSo you wait for your crush to finish the story (finish the current work â¯ / task being processed ğŸ¤“), smile gently and say that you are going for the burgers â¸.\n\nThen you go to the counter ğŸ”€, to the initial task that is now finished â¯, pick the burgers, say thanks and take them to the table. That finishes that step / task of interaction with the counter â¹. That in turn, creates a new task, of \"eating burgers\" ğŸ”€ â¯, but the previous one of \"getting burgers\" is finished â¹.\n\nNow let's imagine these aren't \"Concurrent Burgers\", but \"Parallel Burgers\".\n\nYou go with your crush to get parallel fast food.\n\nYou stand in line while several (let's say 8) cashiers that at the same time are cooks take the orders from the people in front of you.\n\nEveryone before you is waiting for their burgers to be ready before leaving the counter because each of the 8 cashiers goes and prepares the burger right away before getting the next order.\n\nThen it's finally your turn, you place your order of 2 very fancy burgers for your crush and you.\n\nThe cashier goes to the kitchen.\n\nYou wait, standing in front of the counter ğŸ•™, so that no one else takes your burgers before you do, as there are no numbers for turns.\n\nAs you and your crush are busy not letting anyone get in front of you and take your burgers whenever they arrive, you cannot pay attention to your crush. ğŸ˜\n\nThis is \"synchronous\" work, you are \"synchronized\" with the cashier/cook ğŸ‘¨â€ğŸ³. You have to wait ğŸ•™ and be there at the exact moment that the cashier/cook ğŸ‘¨â€ğŸ³ finishes the burgers and gives them to you, or otherwise, someone else might take them.\n\nThen your cashier/cook ğŸ‘¨â€ğŸ³ finally comes back with your burgers, after a long time waiting ğŸ•™ there in front of the counter.\n\nYou take your burgers and go to the table with your crush.\n\nYou just eat them, and you are done. â¹\n\nThere was not much talk or flirting as most of the time was spent waiting ğŸ•™ in front of the counter. ğŸ˜\n\nBeautiful illustrations by Ketrina Thompson. ğŸ¨\n\nIn this scenario of the parallel burgers, you are a computer / program ğŸ¤– with two processors (you and your crush), both waiting ğŸ•™ and dedicating their attention â¯ to be \"waiting on the counter\" ğŸ•™ for a long time.\n\nThe fast food store has 8 processors (cashiers/cooks). While the concurrent burgers store might have had only 2 (one cashier and one cook).\n\nBut still, the final experience is not the best. ğŸ˜\n\nThis would be the parallel equivalent story for burgers. ğŸ”\n\nFor a more \"real life\" example of this, imagine a bank.\n\nUp to recently, most of the banks had multiple cashiers ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ and a big line ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™.\n\nAll of the cashiers doing all the work with one client after the other ğŸ‘¨â€ğŸ’¼â¯.\n\nAnd you have to wait ğŸ•™ in the line for a long time or you lose your turn.\n\nYou probably wouldn't want to take your crush ğŸ˜ with you to run errands at the bank ğŸ¦.\n\nIn this scenario of \"fast food burgers with your crush\", as there is a lot of waiting ğŸ•™, it makes a lot more sense to have a concurrent system â¸ğŸ”€â¯.\n\nThis is the case for most of the web applications.\n\nMany, many users, but your server is waiting ğŸ•™ for their not-so-good connection to send their requests.\n\nAnd then waiting ğŸ•™ again for the responses to come back.\n\nThis \"waiting\" ğŸ•™ is measured in microseconds, but still, summing it all, it's a lot of waiting in the end.\n\nThat's why it makes a lot of sense to use asynchronous â¸ğŸ”€â¯ code for web APIs.\n\nThis kind of asynchronicity is what made NodeJS popular (even though NodeJS is not parallel) and that's the strength of Go as a programming language.\n\nAnd that's the same level of performance you get with FastAPI.\n\nAnd as you can have parallelism and asynchronicity at the same time, you get higher performance than most of the tested NodeJS frameworks and on par with Go, which is a compiled language closer to C (all thanks to Starlette).\n\nNope! That's not the moral of the story.\n\nConcurrency is different than parallelism. And it is better on specific scenarios that involve a lot of waiting. Because of that, it generally is a lot better than parallelism for web application development. But not for everything.\n\nSo, to balance that out, imagine the following short story:\n\nYou have to clean a big, dirty house.\n\nYep, that's the whole story.\n\nThere's no waiting ğŸ•™ anywhere, just a lot of work to be done, on multiple places of the house.\n\nYou could have turns as in the burgers example, first the living room, then the kitchen, but as you are not waiting ğŸ•™ for anything, just cleaning and cleaning, the turns wouldn't affect anything.\n\nIt would take the same amount of time to finish with or without turns (concurrency) and you would have done the same amount of work.\n\nBut in this case, if you could bring the 8 ex-cashier/cooks/now-cleaners, and each one of them (plus you) could take a zone of the house to clean it, you could do all the work in parallel, with the extra help, and finish much sooner.\n\nIn this scenario, each one of the cleaners (including you) would be a processor, doing their part of the job.\n\nAnd as most of the execution time is taken by actual work (instead of waiting), and the work in a computer is done by a CPU, they call these problems \"CPU bound\".\n\nCommon examples of CPU bound operations are things that require complex math processing.\n\nWith FastAPI you can take advantage of concurrency that is very common for web development (the same main attraction of NodeJS).\n\nBut you can also exploit the benefits of parallelism and multiprocessing (having multiple processes running in parallel) for CPU bound workloads like those in Machine Learning systems.\n\nThat, plus the simple fact that Python is the main language for Data Science, Machine Learning and especially Deep Learning, make FastAPI a very good match for Data Science / Machine Learning web APIs and applications (among many others).\n\nTo see how to achieve this parallelism in production see the section about Deployment.\n\nModern versions of Python have a very intuitive way to define asynchronous code. This makes it look just like normal \"sequential\" code and do the \"awaiting\" for you at the right moments.\n\nWhen there is an operation that will require waiting before giving the results and has support for these new Python features, you can code it like:\n\nThe key here is the await. It tells Python that it has to wait â¸ for get_burgers(2) to finish doing its thing ğŸ•™ before storing the results in burgers. With that, Python will know that it can go and do something else ğŸ”€ â¯ in the meanwhile (like receiving another request).\n\nFor await to work, it has to be inside a function that supports this asynchronicity. To do that, you just declare it with async def:\n\nWith async def, Python knows that, inside that function, it has to be aware of await expressions, and that it can \"pause\" â¸ the execution of that function and go do something else ğŸ”€ before coming back.\n\nWhen you want to call an async def function, you have to \"await\" it. So, this won't work:\n\nSo, if you are using a library that tells you that you can call it with await, you need to create the path operation functions that uses it with async def, like in:\n\nYou might have noticed that await can only be used inside of functions defined with async def.\n\nBut at the same time, functions defined with async def have to be \"awaited\". So, functions with async def can only be called inside of functions defined with async def too.\n\nSo, about the egg and the chicken, how do you call the first async function?\n\nIf you are working with FastAPI you don't have to worry about that, because that \"first\" function will be your path operation function, and FastAPI will know how to do the right thing.\n\nBut if you want to use async / await without FastAPI, you can do it as well.\n\nStarlette (and FastAPI) are based on AnyIO, which makes it compatible with both Python's standard library asyncio and Trio.\n\nIn particular, you can directly use AnyIO for your advanced concurrency use cases that require more advanced patterns in your own code.\n\nAnd even if you were not using FastAPI, you could also write your own async applications with AnyIO to be highly compatible and get its benefits (e.g. structured concurrency).\n\nI created another library on top of AnyIO, as a thin layer on top, to improve a bit the type annotations and get better autocompletion, inline errors, etc. It also has a friendly introduction and tutorial to help you understand and write your own async code: Asyncer. It would be particularly useful if you need to combine async code with regular (blocking/synchronous) code.\n\nThis style of using async and await is relatively new in the language.\n\nBut it makes working with asynchronous code a lot easier.\n\nThis same syntax (or almost identical) was also included recently in modern versions of JavaScript (in Browser and NodeJS).\n\nBut before that, handling asynchronous code was quite more complex and difficult.\n\nIn previous versions of Python, you could have used threads or Gevent. But the code is way more complex to understand, debug, and think about.\n\nIn previous versions of NodeJS / Browser JavaScript, you would have used \"callbacks\". Which leads to \"callback hell\".\n\nCoroutine is just the very fancy term for the thing returned by an async def function. Python knows that it is something like a function, that it can start and that it will end at some point, but that it might be paused â¸ internally too, whenever there is an await inside of it.\n\nBut all this functionality of using asynchronous code with async and await is many times summarized as using \"coroutines\". It is comparable to the main key feature of Go, the \"Goroutines\".\n\nLet's see the same phrase from above:\n\nModern versions of Python have support for \"asynchronous code\" using something called \"coroutines\", with async and await syntax.\n\nThat should make more sense now. âœ¨\n\nAll that is what powers FastAPI (through Starlette) and what makes it have such an impressive performance.\n\nYou can probably skip this.\n\nThese are very technical details of how FastAPI works underneath.\n\nIf you have quite some technical knowledge (coroutines, threads, blocking, etc.) and are curious about how FastAPI handles async def vs normal def, go ahead.\n\nWhen you declare a path operation function with normal def instead of async def, it is run in an external threadpool that is then awaited, instead of being called directly (as it would block the server).\n\nIf you are coming from another async framework that does not work in the way described above and you are used to defining trivial compute-only path operation functions with plain def for a tiny performance gain (about 100 nanoseconds), please note that in FastAPI the effect would be quite opposite. In these cases, it's better to use async def unless your path operation functions use code that performs blocking I/O.\n\nStill, in both situations, chances are that FastAPI will still be faster than (or at least comparable to) your previous framework.\n\nThe same applies for dependencies. If a dependency is a standard def function instead of async def, it is run in the external threadpool.\n\nYou can have multiple dependencies and sub-dependencies requiring each other (as parameters of the function definitions), some of them might be created with async def and some with normal def. It would still work, and the ones created with normal def would be called on an external thread (from the threadpool) instead of being \"awaited\".\n\nAny other utility function that you call directly can be created with normal def or async def and FastAPI won't affect the way you call it.\n\nThis is in contrast to the functions that FastAPI calls for you: path operation functions and dependencies.\n\nIf your utility function is a normal function with def, it will be called directly (as you write it in your code), not in a threadpool, if the function is created with async def then you should await for that function when you call it in your code.\n\nAgain, these are very technical details that would probably be useful if you came searching for them.\n\nOtherwise, you should be good with the guidelines from the section above: In a hurry?.",
  "headings": [
    {
      "level": "h1",
      "text": "Concurrency and async / awaitÂ¶",
      "id": "concurrency-and-async-await"
    },
    {
      "level": "h2",
      "text": "In a hurry?Â¶",
      "id": "in-a-hurry"
    },
    {
      "level": "h2",
      "text": "Technical DetailsÂ¶",
      "id": "technical-details"
    },
    {
      "level": "h2",
      "text": "Asynchronous CodeÂ¶",
      "id": "asynchronous-code"
    },
    {
      "level": "h3",
      "text": "Concurrency and BurgersÂ¶",
      "id": "concurrency-and-burgers"
    },
    {
      "level": "h3",
      "text": "Concurrent BurgersÂ¶",
      "id": "concurrent-burgers"
    },
    {
      "level": "h3",
      "text": "Parallel BurgersÂ¶",
      "id": "parallel-burgers"
    },
    {
      "level": "h3",
      "text": "Burger ConclusionÂ¶",
      "id": "burger-conclusion"
    },
    {
      "level": "h3",
      "text": "Is concurrency better than parallelism?Â¶",
      "id": "is-concurrency-better-than-parallelism"
    },
    {
      "level": "h3",
      "text": "Concurrency + Parallelism: Web + Machine LearningÂ¶",
      "id": "concurrency-parallelism-web-machine-learning"
    },
    {
      "level": "h2",
      "text": "async and awaitÂ¶",
      "id": "async-and-await"
    },
    {
      "level": "h3",
      "text": "More technical detailsÂ¶",
      "id": "more-technical-details"
    },
    {
      "level": "h3",
      "text": "Write your own async codeÂ¶",
      "id": "write-your-own-async-code"
    },
    {
      "level": "h3",
      "text": "Other forms of asynchronous codeÂ¶",
      "id": "other-forms-of-asynchronous-code"
    },
    {
      "level": "h2",
      "text": "CoroutinesÂ¶",
      "id": "coroutines"
    },
    {
      "level": "h2",
      "text": "ConclusionÂ¶",
      "id": "conclusion"
    },
    {
      "level": "h2",
      "text": "Very Technical DetailsÂ¶",
      "id": "very-technical-details"
    },
    {
      "level": "h3",
      "text": "Path operation functionsÂ¶",
      "id": "path-operation-functions"
    },
    {
      "level": "h3",
      "text": "DependenciesÂ¶",
      "id": "dependencies"
    },
    {
      "level": "h3",
      "text": "Sub-dependenciesÂ¶",
      "id": "sub-dependencies"
    },
    {
      "level": "h3",
      "text": "Other utility functionsÂ¶",
      "id": "other-utility-functions"
    }
  ],
  "code_samples": [
    {
      "code": "results = await some_library()",
      "language": "unknown"
    },
    {
      "code": "@app.get('/')\nasync def read_results():\n    results = await some_library()\n    return results",
      "language": "python"
    },
    {
      "code": "@app.get('/')\ndef results():\n    results = some_library()\n    return results",
      "language": "python"
    },
    {
      "code": "burgers = await get_burgers(2)",
      "language": "unknown"
    },
    {
      "code": "async def get_burgers(number: int):\n    # Do some asynchronous stuff to create the burgers\n    return burgers",
      "language": "python"
    },
    {
      "code": "# This is not asynchronous\ndef get_sequential_burgers(number: int):\n    # Do some sequential stuff to create the burgers\n    return burgers",
      "language": "python"
    },
    {
      "code": "# This won't work, because get_burgers was defined with: async def\nburgers = get_burgers(2)",
      "language": "unknown"
    },
    {
      "code": "@app.get('/burgers')\nasync def read_burgers():\n    burgers = await get_burgers(2)\n    return burgers",
      "language": "python"
    }
  ],
  "patterns": [
    {
      "description": "For example:",
      "code": "async"
    }
  ],
  "links": [
    "https://fastapi.tiangolo.com/async/",
    "https://fastapi.tiangolo.com/deployment/",
    "https://fastapi.tiangolo.com/",
    "https://fastapi.tiangolo.com/tutorial/dependencies/",
    "https://fastapi.tiangolo.com/tutorial/dependencies/sub-dependencies/"
  ]
}